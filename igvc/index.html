<!DOCTYPE html>
<html lang="en-US">
  <head prefix="og: https://ogp.me/ns#">
    <meta charset="utf-8" />
    <meta name="generator" content="gh:importantimport/urara" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="manifest" crossorigin="use-credentials" href="/manifest.webmanifest" />
    <link rel="alternate" type="application/feed+json" href="/feed.json" />
    <link rel="alternate" type="application/atom+xml" href="/atom.xml" />
    <link rel="sitemap" type="application/xml" href="/sitemap.xml" />
    <meta http-equiv="content-security-policy" content="style-src 'self' 'unsafe-inline' https://giscus.app">
		<link href="../_app/immutable/assets/0.da28673c.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.8e4c9d6e.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.17f79c6b.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/singletons.7171db05.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.1d85ef92.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.73d3a5d0.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/preload-helper.41c905a7.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.401f9d8e.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/posts.7eeb28a4.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/icon.be107729.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/3.b8130252.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/post_layout.17c611d9.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/footer.b2ef5326.js"><title>Intelligent Ground Vehicle Competition | Andrew Nash Blog</title><!-- HEAD_svelte-1592q3p_START --><!-- HEAD_svelte-1592q3p_END --><!-- HEAD_svelte-1kxdj3d_START --><link rel="shortcut icon" href="https://urara-demo.netlify.app/favicon.png" sizes="48x48" type="image/png"><link rel="apple-touch-icon" href="https://urara-demo.netlify.app/assets/any@180.png" sizes="180x180" type="image/png"><link rel="icon" href="https://urara-demo.netlify.app/assets/any@192.png" sizes="192x192" type="image/png"><!-- HEAD_svelte-1kxdj3d_END --><!-- HEAD_svelte-1g590ms_START --><meta name="theme-color"><!-- HEAD_svelte-1g590ms_END --><!-- HEAD_svelte-abrfj_START --><meta name="author" content="Andrew Nash"><link rel="canonical" href="https://urara-demo.netlify.app/igvc">
    
    <meta name="keywords" content="Computer Vision, Transformer">
    <!-- HEAD_svelte-abrfj_END --><!-- HEAD_svelte-1y1uq0g_START --><meta property="og:site_name" content="Andrew Nash Blog"><meta property="og:locale" content="en-US"><meta property="og:type" content="article">
    <meta property="og:title" content="Intelligent Ground Vehicle Competition">
    
    <meta property="og:image" content="https://urara-demo.netlify.app/igvc/team.jpg">
      <meta name="twitter:card" content="summary_large_image">
    <meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="Transformer">
    <meta property="og:url" content="https://urara-demo.netlify.app/igvc">
    <meta property="article:author" content="Andrew Nash">
    <meta property="article:published_time" content="2023-06-11T00:00:00.000Z">
    <meta property="article:modified_time" content="2023-06-14T15:17:10.756Z"><!-- HEAD_svelte-1y1uq0g_END -->
  </head>
  <body itemscope itemtype="https://schema.org/WebPage">
    <div style="display: contents">










<header id="header" class="fixed z-50 w-screen transition-all duration-500 ease-in-out border-b-2 border-transparent max-h-[4.125rem] false"><div class="navbar"><div class="navbar-start">

<div class="dropdown lg:hidden"><label for="navbar-dropdown" tabindex="0" class="btn btn-square btn-ghost"><span class="i-heroicons-outline-menu-alt-1"></span></label>
  <ul id="navbar-dropdown" tabindex="0" class="menu menu-compact dropdown-content bg-base-100 text-base-content shadow-lg rounded-box min-w-max max-w-52 p-2"><li><a href="/igvc">IGVC</a>
        </li><li><a href="/srauv">SRAUV</a>
        </li></ul></div>
<div class="swap order-last hidden lg:inline-grid"><button class="swap-on btn btn-ghost text-base font-normal normal-case transition-all duration-200 hidden"></button>
  <ul class="swap-off menu menu-horizontal p-0"><li><a class="!rounded-btn" href="/igvc">IGVC</a>
        </li><li><a class="!rounded-btn" href="/srauv">SRAUV</a>
        </li></ul></div>
        <a href="/" class="btn btn-ghost normal-case text-lg">Andrew Nash Blog</a></div>
      <div class="navbar-end">
        <div id="change-theme" class="dropdown dropdown-end">
          
          <div tabindex="0" class="btn btn-square btn-ghost"><span class="i-heroicons-outline-color-swatch"></span></div>
          
          
          <ul tabindex="0" class="flex flex-nowrap shadow-2xl menu dropdown-content bg-base-100 text-base-content rounded-box w-52 p-2 gap-2 overflow-y-auto max-h-[21.5rem]"><button data-theme="dracula" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🧛 Dark</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="valentine" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🌸 Valentine</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="aqua" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">💦 Aqua</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="synthwave" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🌃 Synthwave</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="night" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🌃 Night</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="lofi" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🎶 Lo-Fi</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="lemonade" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🍋 Lemonade</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="cupcake" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🧁 Cupcake</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="garden" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🏡 Garden</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="retro" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🌇 Retro</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button><button data-theme="black" class="btn btn-ghost w-full hover:bg-primary group rounded-lg flex bg-base-100 p-2 transition-all"><p class="flex-1 text-left text-base-content group-hover:text-primary-content transition-color">🖤 Black</p>
                <div class="grid grid-cols-4 gap-0.5 m-auto"><div class="bg-primary w-1 h-4 rounded-btn"></div><div class="bg-secondary w-1 h-4 rounded-btn"></div><div class="bg-accent w-1 h-4 rounded-btn"></div><div class="bg-neutral w-1 h-4 rounded-btn"></div></div>
              </button></ul></div></div></div></header>

<button id="totop" aria-label="scroll to top" class="fixed grid group btn btn-circle btn-lg border-none backdrop-blur bottom-6 right-6 z-50 duration-500 ease-in-out btn-ghost bg-base-100/30 md:bg-base-200/30 translate-y-24"><div class="radial-progress text-accent transition-all duration-500 ease-in-out group-hover:text-accent-focus col-start-1 row-start-1" style="--size:4rem; --thickness: 0.25rem; --value:undefined;"></div>
  <div class="border-4 border-base-content/10 group-hover:border-transparent col-start-1 row-start-1 rounded-full w-full h-full p-4 grid duration-500 ease-in-out"><span class="i-heroicons-solid-chevron-up !w-6 !h-6"></span></div></button>

<div class="bg-base-100 md:bg-base-200 min-h-screen pt-16 md:pb-8 lg:pb-16">



<div class="flex flex-col flex-nowrap justify-center xl:flex-row xl:flex-wrap"><div class="flex-1 w-full order-first ease-out transform mx-auto xl:mr-0 xl:ml-0"></div>
  <div class="flex-1 w-full xl:order-last ease-out transform mx-auto xl:ml-0 xl:mr-0"></div>
  <div class="flex-none w-full max-w-screen-md mx-auto xl:mx-0"><article itemscope itemtype="https://schema.org/BlogPosting" itemprop="blogPost" class="h-entry card bg-base-100 rounded-none md:rounded-box md:shadow-xl overflow-hidden z-10 md:mb-8 lg:mb-16">
  
  
  <div class="card-body gap-0 "><div class="flex flex-col gap-2"><figure class="md:order-last rounded-box shadow-xl mb-4 flex-col gap-2 -mx-4 -mt-8 md:mt-0"><picture><source srcset="/_app/immutable/assets/team.7309ae7f.avif 736w" type="image/avif">
    <img src="/igvc/team.jpg" alt="/igvc/team.jpg" class="u-featured" loading="lazy" decoding="async"></picture></figure>
      <div class="flex font-semibold gap-1.5"><a rel="author" class="opacity-75 hover:opacity-100 hover:text-primary duration-500 ease-in-out p-author h-card" href="https://urara-demo.netlify.app">Andrew Nash</a>
  <span class="opacity-50">/</span>
  <a href="/igvc" class="u-url u-uid swap group/time"><time class="group-hover/time:opacity-0 font-semibold opacity-75 duration-500 ease-in-out mr-auto dt-published" datetime="2023-06-11T00:00:00.000Z" itemprop="datePublished">Sunday, Jun 11, 23</time>
    <time class="opacity-0 group-hover/time:opacity-100 font-semibold text-primary duration-500 ease-in-out mr-auto dt-updated" datetime="2023-06-14T15:17:10.756Z" itemprop="dateModified">Wednesday, Jun 14, 23</time></a></div>
      <h1 itemprop="name headline" class="card-title text-3xl mb-8 p-name">Intelligent Ground Vehicle Competition</h1>
      </div>
    <main itemprop="articleBody" class="urara-prose prose e-content"><h1 id="a-deep-dive-into-my-autonomous-vehicle-software-design-journey"><a href="#a-deep-dive-into-my-autonomous-vehicle-software-design-journey">A Deep Dive into My Autonomous Vehicle Software Design Journey</a></h1>
<p>Hello everyone! I’m Andrew Nash, and for the past year, I’ve been leading the software development efforts for Paradigm’s autonomous vehicle in the Intelligent Ground Vehicle Competition (IGVC). This has been an exciting journey, full of learning, innovation, and countless lines of code. In this post, I’ll walk you through the technical nuances of the software I developed and implemented. My role involved designing and implimenting all perception (including all ML models), navigation, control, and sensor code.</p>
<p><img src="./robot.jpg" alt="robot" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<h2 id="igvc-auto-nav-challenge"><a href="#igvc-auto-nav-challenge">IGVC Auto-Nav Challenge</a></h2>
<p>To compete at the 30th annual IGVC, Paradigm had to design and build an original vehicle that can autonomously navigate an obstacle course similar to the one shown below. The vehicle must stay within lane lines and avoid obstacles on an unknown track layout.</p>
<p><img src="./comp_track.PNG" alt="track" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<h2 id="vehicle"><a href="#vehicle">Vehicle</a></h2>
<p>The mechanical design of our competition entry is a testament to the team’s innovation and engineering prowess. The vehicle’s distinctive skid-steer drivetrain, with its two separate drivetrain modules, truly stands out. This configuration enables superior maneuverability, allowing the vehicle to smoothly navigate diverse landscapes, from smooth paved surfaces to challenging off-road terrains.</p>
<p><img src="./render.png" alt="render" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<h2 id="software-overview"><a href="#software-overview">Software Overview</a></h2>
<p>I designed Paradigm’s autonomous vehicle software strategy with the singular aim to excel in the Auto-Nav Challenge. This competition involved navigating a course littered with dynamic obstacles, which required a software system capable of advanced obstacle detection, real-time decision-making, and swift path adjustment.</p>
<p><img src="./ROS.png" alt="ROS" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<p>Central to this was the integration of our custom AI and localization pipelines with the ROS2 Nav2 system, a feat that I am particularly proud of. This integration allowed our software to adjust the vehicle’s path in real-time based on the identified obstacles and their estimated locations. The robustness and precision of our software were key in navigating the Auto-Nav Challenge effectively.</p>
<h3 id="vision-based-obstacle-detection-and-avoidance"><a href="#vision-based-obstacle-detection-and-avoidance">Vision-based Obstacle Detection and Avoidance</a></h3>
<p>One of my significant contributions was incorporating advanced computer vision algorithms into our design. Our vehicle was equipped with six high-resolution cameras, capturing 360-degree visuals at 60 frames per second. Two separate instances of Cross-View Transformer (CVT) [1] processed the real-time data from these cameras. Each CVT instance generated a 256x256 matrix that represented the model’s confidence levels in the presence of an obstacle in an approximately one square inch area. I integrated these outputs into a ROS costmap for efficient path planning.</p>
<p><img src="./ParadigmCVT.png" alt="ParadigmCVT" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<p>CVTs use a cross-view, cross-attention mechanism to convert individual camera features into a shared bird’s eye view (BEV) representation. I fine-tuned this model to accurately detect obstacles and predict feasible navigation areas.</p>
<h4 id="obstacle-avoidance"><a href="#obstacle-avoidance">Obstacle Avoidance</a></h4>
<p>The two CVTs worked together to form a detailed bird’s-eye-view of the environment. While one CVT instance detected obstacles, the other, dubbed the “driveable” model, mapped feasible navigation areas around the robot. My focus on collaboration and synchronization between these two models played a crucial role in our success in the Auto-Nav Challenge.</p>
<p>Obstacle model sample Bird’s Eye View prediction (lighter color = higher confidence) <img src="./object_detection.PNG" alt="obstcale" class="rounded-lg my-2" loading="lazy" decoding="async">
Driveable model sample Bird’s Eye View prediction (lighter color = higher confidence) <img src="./driveable.PNG" alt="driveable" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<h3 id="mapping--path-planning"><a href="#mapping--path-planning">Mapping &amp; Path Planning</a></h3>
<p>For efficient path planning, I integrated a semantically segmented costmap into the ROS2 navigation system. This strategy involved mapping drivable areas and assigning them a negative cost value, making them more attractive paths for our vehicle.</p>
<p>Map generation <img src="./map.gif" alt="mapping" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<p>I designed our perception system to feed BEV predictions into the ROS Spatio-Temporal Voxel Layer, which helped generate costmaps effectively. In creating the costmap, a two-dimensional grid representing traversal difficulty, I fine-tuned the system to discard low-confidence predictions and apply a temporal filter to reduce false positives. This fine-tuning was a critical aspect of our strategy, helping us maintain an accurate and efficient path planning mechanism.</p>
<h3 id="localization"><a href="#localization">Localization</a></h3>
<p>I used the ZED2 stereo camera and the BerryGPS-IMU to accurately localize the vehicle using visual odometry, acceleration, angular velocity, and geolocation data. I used the ROS2 implemented an Extended Kalman Filter (EKF) that consolidated these diverse data inputs, providing an accurate estimate of the vehicle’s position. This localization pipeline is intentionally simple as the high FPS BEV mapping does most of the heavy lifting for navigation.</p>
<h2 id="simulation"><a href="#simulation">Simulation</a></h2>
<p>A key element of my development process was the integration of a robust simulation environment into our development cycle. I customized the CARLA [2] simulator, based in Unreal Engine, to replicate the Auto-Nav challenge setting. This involved designing a unique Unreal Engine level that mirrored the competition area with an impressive +/- 0.5 foot accuracy. This level could also be rearranged to simulate various competition layouts for ROS navigation testing and data collection, making it a versatile tool in our development process.</p>
<p>Paradigm custom IGVC level in Unreal Engine <img src="./sim.PNG" alt="driveable" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<p>We leveraged CARLA’s ROS2 Bridge to facilitate a seamless exchange of sensor and control data between the simulator and the ROS2 environment. This enabled us to live stream a range of sensor data, including camera images, IMU readings, and GPS coordinates, directly into our navigation pipeline.</p>
<p>The use of the CARLA simulator for testing presented us with a myriad of benefits. It allowed us to test and debug our navigation system before the physical vehicle was fully assembled, which significantly accelerated our development cycle. Moreover, it enabled us to simulate various environmental conditions and course layouts in a controlled environment without the associated risks and costs of physical testing.</p>
<h3 id="model-training-from-simulator-data"><a href="#model-training-from-simulator-data">Model Training from Simulator Data</a></h3>
<p>I employed the CARLA Python API to generate a diverse dataset for training our computer vision models. This involved integrating our vehicle, into the CARLA level, and adjusting the simulation’s camera positions and intrinsic parameters to match those of the real cameras mounted on the vehicle.</p>
<p>I then randomly placed the vehicle at different positions within the course, adjusting its orientation each time, to create a robust and diverse dataset. Factors such as the sun’s position, weather conditions, track layout, ground material, and obstacle materials were manipulated to ensure the dataset’s versatility. Total dataset size was about 30,000 image sets (6 cam input &amp; 1 BEV ground truth).</p>
<p>Sample images collected from sim <img src="./sim_pics.PNG" alt="sim_pics" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<p>Inspired by GPT, I pre-trained our CVT models on the nuScenes dataset [3], a large-scale real-world dataset, where they achieved near state-of-the-art BEV prediction performance. Pre-training these models helped them generalize BEV prediction strategies and familiarize themselves with various scenarios. The models were then fine-tuned using our custom-generated IGVC dataset. In initial testing, the CVT models operated in parallel at 58 FPS on the robot’s RTX 4080 GPU and achieved an Intersection Over Union (IoU) score of 92%, a testament to the efficacy of our simulation-based approach.</p>
<h2 id="compute-hardware"><a href="#compute-hardware">Compute Hardware</a></h2>
<p>As the creator of the compute subsystem, I incorporated an assembly of high-performance computing modules and camera arrays. I equipped the “flight computer” with an RTX 4080 GPU for real-time machine-learning tasks. My choice of a Jetson Nano and a Raspberry Pi B4 module helped handle camera live-streaming and support IMU and GPS modules over the ROS network.</p>
<p><img src="./compute_subsystem.png" alt="compute_subsystem" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<p>My design of the camera system integrated five cameras with the flight computer, Jetson Nano, and Raspberry Pi B4, along with a standalone ZED 2 camera, constantly feeding real-time visual data into the computer vision models via a router over the ROS network. I can not take credit for the control, or power subsystems, I worked with some fantastic teammates that handled that portion of the design and implementation.</p>
<h2 id="gpt-for-fundraising"><a href="#gpt-for-fundraising">GPT for Fundraising</a></h2>
<p>This year, in the absence of a dedicated business team, I used GPT-4 for an unconventional task - fundraising. I designed effective prompts that enabled GPT-4 to create persuasive emails and compelling funding proposals. This innovative application of AI resulted in a successful fundraising campaign, securing $28k to entirely fund our vehicle’s fabrication and competition shipment.</p>
<h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2>
<p>Working on Paradigm’s autonomous vehicle software for the IGVC was a rewarding and educational experience. My journey entailed designing and implementing ROS perception, navigation, control, and sensor code, all of which were tailored to master the Auto-Nav Challenge. The advanced computer vision algorithms, efficient path planning, and robust localization approach I employed all culminated in a system that successfully navigated an unpredictable environment in real-time.</p>
<p>The CARLA simulation environment was instrumental in accelerating our development cycle, providing a versatile platform for testing, debugging, and data generation. I’m proud of the final results and the integral role I played in Paradigm’s success in the competition.</p>
<p>Stay tuned for more exciting projects and technical insights in my future posts! Thanks for reading.</p>
<p><img src="./bot.png" alt="bot" class="rounded-lg my-2" loading="lazy" decoding="async"></p>
<h4 id="references"><a href="#references">References</a></h4>
<p>[1] B. Zhou and P. Krähenbühl, “Cross-view Transformers for real-time Map-view Semantic Segmentation,” Computer Vision and Pattern Recognition, 2022.</p>
<p>[2] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez and V. Koltun, “CARLA: An Open Urban Driving Simulator,” Conference on Robot Learning, 2017.</p>
<p>[3] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Lion, Q. Xu, A. Krishnan, Y. Pan, G. Baldan and O. Beijbom, “nuScenes: A multimodal dataset for autonomous driving,” Computer Vision and Pattern Recognition, 2019.</p>
<p>Disclaimer: Please note that some details have been simplified for the sake of readability.</p></main>
    <div class="divider mt-4 mb-0"></div>
      <div><a href="/?tags=Computer Vision" class="btn btn-sm btn-ghost normal-case mt-2 mr-2 p-category">#Computer Vision
          </a><a href="/?tags=Transformer" class="btn btn-sm btn-ghost normal-case mt-2 mr-2 p-category">#Transformer
          </a></div></div>
  
    </article>
    <footer id="footer" class="footer footer-center bg-base-300 text-base-content shadow-inner p-8 md:rounded-box sticky bottom-0 z-0 md:static "><div class="prose"><p><a href="/atom.xml" rel="noopener noreferrer external" target="_blank">Feed</a>
          <span class="mr-1">·</span><a href="/sitemap.xml" rel="noopener noreferrer external" target="_blank">Sitemap</a>
          
        <br>
      Copyright © 2023
      Andrew Nash
      <br>
      Powered by
      <a rel="noopener noreferrer external" target="_blank" class="tooltip tooltip-secondary hover:text-secondary" data-tip="🌸 [δ] - Based on MDsveX & SvelteKit 🌸" href="https://github.com/importantimport/urara">Urara
      </a>
      </p></div></footer></div></div></div>


			<script type="application/json" data-sveltekit-fetched data-url="/posts.json">{"status":200,"statusText":"","headers":{},"body":"[{\"title\":\"Intelligent Ground Vehicle Competition\",\"image\":\"/igvc/team.jpg\",\"alt\":\"IGVC\",\"created\":\"2023-06-11T00:00:00.000Z\",\"tags\":[\"Computer Vision\",\"Transformer\"],\"updated\":\"2023-06-14T15:17:10.756Z\",\"images\":[],\"slug\":\"/igvc/+page.svelte.md\",\"path\":\"/igvc\",\"toc\":[{\"depth\":1,\"title\":\"A Deep Dive into My Autonomous Vehicle Software Design Journey\",\"slug\":\"a-deep-dive-into-my-autonomous-vehicle-software-design-journey\"},{\"depth\":2,\"title\":\"IGVC Auto-Nav Challenge\",\"slug\":\"igvc-auto-nav-challenge\"},{\"depth\":2,\"title\":\"Vehicle\",\"slug\":\"vehicle\"},{\"depth\":2,\"title\":\"Software Overview\",\"slug\":\"software-overview\"},{\"depth\":3,\"title\":\"Vision-based Obstacle Detection and Avoidance\",\"slug\":\"vision-based-obstacle-detection-and-avoidance\"},{\"depth\":4,\"title\":\"Obstacle Avoidance\",\"slug\":\"obstacle-avoidance\"},{\"depth\":3,\"title\":\"Mapping & Path Planning\",\"slug\":\"mapping--path-planning\"},{\"depth\":3,\"title\":\"Localization\",\"slug\":\"localization\"},{\"depth\":2,\"title\":\"Simulation\",\"slug\":\"simulation\"},{\"depth\":3,\"title\":\"Model Training from Simulator Data\",\"slug\":\"model-training-from-simulator-data\"},{\"depth\":2,\"title\":\"Compute Hardware\",\"slug\":\"compute-hardware\"},{\"depth\":2,\"title\":\"GPT for Fundraising\",\"slug\":\"gpt-for-fundraising\"},{\"depth\":2,\"title\":\"Conclusion\",\"slug\":\"conclusion\"},{\"depth\":4,\"title\":\"References\",\"slug\":\"references\"}],\"type\":\"article\",\"html\":\"\"},{\"title\":\"Subsea Resident Autonomous Underwater Vehicle\",\"image\":\"/srauv/team.jpg\",\"alt\":\"SRAUV\",\"created\":\"2020-05-02T00:00:00.000Z\",\"tags\":[\"Computer Vision\",\"RL\"],\"updated\":\"2023-06-14T15:17:10.968Z\",\"images\":[],\"slug\":\"/srauv/+page.svelte.md\",\"path\":\"/srauv\",\"toc\":[{\"depth\":1,\"title\":\"Navigating the Depths with RL\",\"slug\":\"navigating-the-depths-with-rl\"},{\"depth\":2,\"title\":\"Introduction\",\"slug\":\"introduction\"},{\"depth\":2,\"title\":\"Vehicle\",\"slug\":\"vehicle\"},{\"depth\":2,\"title\":\"Software Overview\",\"slug\":\"software-overview\"},{\"depth\":2,\"title\":\"Simulator\",\"slug\":\"simulator\"},{\"depth\":2,\"title\":\"Model Training\",\"slug\":\"model-training\"},{\"depth\":2,\"title\":\"Autonomous Strategy\",\"slug\":\"autonomous-strategy\"},{\"depth\":2,\"title\":\"Model Development\",\"slug\":\"model-development\"},{\"depth\":3,\"title\":\"Model Selection\",\"slug\":\"model-selection\"},{\"depth\":3,\"title\":\"Reward Structure\",\"slug\":\"reward-structure\"},{\"depth\":3,\"title\":\"Curriculum Learning\",\"slug\":\"curriculum-learning\"},{\"depth\":3,\"title\":\"Localization\",\"slug\":\"localization\"},{\"depth\":2,\"title\":\"Real World Testing\",\"slug\":\"real-world-testing\"},{\"depth\":2,\"title\":\"Conclusion\",\"slug\":\"conclusion\"}],\"type\":\"article\",\"html\":\"\"}]"}</script>
			<script>
				{
					__sveltekit_zadtwe = {
						base: new URL("..", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("../_app/immutable/entry/start.8e4c9d6e.js"),
						import("../_app/immutable/entry/app.73d3a5d0.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 3],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
  </body>
</html>
